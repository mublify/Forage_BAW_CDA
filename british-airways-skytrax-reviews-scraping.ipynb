{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"4f7924c4c56b083e0e50eadfe7ef592a7a8ef70df33a0047f82280e6be1afe15"}},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Task 1\n\n---\n\n## Web scraping and analysis\n\nThis Jupyter notebook includes some code to get you started with web scraping. We will use a package called `BeautifulSoup` to collect the data from the web. Once you've collected your data and saved it into a local `.csv` file you should start with your analysis.\n\n### Scraping data from Skytrax\n\nIf you visit [https://www.airlinequality.com] you can see that there is a lot of data there. For this task, we are only interested in reviews related to British Airways and the Airline itself.\n\nIf you navigate to this link: [https://www.airlinequality.com/airline-reviews/british-airways] you will see this data. Now, we can use `Python` and `BeautifulSoup` to collect all the links to the reviews and then to collect the text data on each of the individual review links.","metadata":{}},{"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-03-13T05:51:37.958426Z","iopub.execute_input":"2024-03-13T05:51:37.959679Z","iopub.status.idle":"2024-03-13T05:51:39.700432Z","shell.execute_reply.started":"2024-03-13T05:51:37.959639Z","shell.execute_reply":"2024-03-13T05:51:39.699213Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\npages = 70\npage_size = 100\n\nreviews = []\n\n# for i in range(1, pages + 1):\nfor i in range(1, pages + 1):\n\n    print(f\"Scraping page {i}\")\n\n    # Create URL to collect links from paginated data\n    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n\n    # Collect HTML data from this page\n    response = requests.get(url)\n\n    # Parse content\n    content = response.content\n    parsed_content = BeautifulSoup(content, 'html.parser')\n    for para in parsed_content.find_all(\"div\", {\"class\": \"text_content\"}):\n        reviews.append(para.get_text())\n    \n    print(f\"   ---> {len(reviews)} total reviews\")","metadata":{"execution":{"iopub.status.busy":"2024-03-13T05:51:39.702670Z","iopub.execute_input":"2024-03-13T05:51:39.703380Z","iopub.status.idle":"2024-03-13T05:52:43.142701Z","shell.execute_reply.started":"2024-03-13T05:51:39.703333Z","shell.execute_reply":"2024-03-13T05:52:43.141342Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Scraping page 1\n   ---> 100 total reviews\nScraping page 2\n   ---> 200 total reviews\nScraping page 3\n   ---> 300 total reviews\nScraping page 4\n   ---> 400 total reviews\nScraping page 5\n   ---> 500 total reviews\nScraping page 6\n   ---> 600 total reviews\nScraping page 7\n   ---> 700 total reviews\nScraping page 8\n   ---> 800 total reviews\nScraping page 9\n   ---> 900 total reviews\nScraping page 10\n   ---> 1000 total reviews\nScraping page 11\n   ---> 1100 total reviews\nScraping page 12\n   ---> 1200 total reviews\nScraping page 13\n   ---> 1300 total reviews\nScraping page 14\n   ---> 1400 total reviews\nScraping page 15\n   ---> 1500 total reviews\nScraping page 16\n   ---> 1600 total reviews\nScraping page 17\n   ---> 1700 total reviews\nScraping page 18\n   ---> 1800 total reviews\nScraping page 19\n   ---> 1900 total reviews\nScraping page 20\n   ---> 2000 total reviews\nScraping page 21\n   ---> 2100 total reviews\nScraping page 22\n   ---> 2200 total reviews\nScraping page 23\n   ---> 2300 total reviews\nScraping page 24\n   ---> 2400 total reviews\nScraping page 25\n   ---> 2500 total reviews\nScraping page 26\n   ---> 2600 total reviews\nScraping page 27\n   ---> 2700 total reviews\nScraping page 28\n   ---> 2800 total reviews\nScraping page 29\n   ---> 2900 total reviews\nScraping page 30\n   ---> 3000 total reviews\nScraping page 31\n   ---> 3100 total reviews\nScraping page 32\n   ---> 3200 total reviews\nScraping page 33\n   ---> 3300 total reviews\nScraping page 34\n   ---> 3400 total reviews\nScraping page 35\n   ---> 3500 total reviews\nScraping page 36\n   ---> 3600 total reviews\nScraping page 37\n   ---> 3700 total reviews\nScraping page 38\n   ---> 3765 total reviews\nScraping page 39\n   ---> 3765 total reviews\nScraping page 40\n   ---> 3765 total reviews\nScraping page 41\n   ---> 3765 total reviews\nScraping page 42\n   ---> 3765 total reviews\nScraping page 43\n   ---> 3765 total reviews\nScraping page 44\n   ---> 3765 total reviews\nScraping page 45\n   ---> 3765 total reviews\nScraping page 46\n   ---> 3765 total reviews\nScraping page 47\n   ---> 3765 total reviews\nScraping page 48\n   ---> 3765 total reviews\nScraping page 49\n   ---> 3765 total reviews\nScraping page 50\n   ---> 3765 total reviews\nScraping page 51\n   ---> 3765 total reviews\nScraping page 52\n   ---> 3765 total reviews\nScraping page 53\n   ---> 3765 total reviews\nScraping page 54\n   ---> 3765 total reviews\nScraping page 55\n   ---> 3765 total reviews\nScraping page 56\n   ---> 3765 total reviews\nScraping page 57\n   ---> 3765 total reviews\nScraping page 58\n   ---> 3765 total reviews\nScraping page 59\n   ---> 3765 total reviews\nScraping page 60\n   ---> 3765 total reviews\nScraping page 61\n   ---> 3765 total reviews\nScraping page 62\n   ---> 3765 total reviews\nScraping page 63\n   ---> 3765 total reviews\nScraping page 64\n   ---> 3765 total reviews\nScraping page 65\n   ---> 3765 total reviews\nScraping page 66\n   ---> 3765 total reviews\nScraping page 67\n   ---> 3765 total reviews\nScraping page 68\n   ---> 3765 total reviews\nScraping page 69\n   ---> 3765 total reviews\nScraping page 70\n   ---> 3765 total reviews\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.DataFrame()\ndf[\"reviews\"] = reviews\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-13T05:52:43.151534Z","iopub.execute_input":"2024-03-13T05:52:43.151884Z","iopub.status.idle":"2024-03-13T05:52:43.179836Z","shell.execute_reply.started":"2024-03-13T05:52:43.151854Z","shell.execute_reply":"2024-03-13T05:52:43.178826Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                             reviews\n0  ✅ Trip Verified |  Absolutely horrible custome...\n1  Not Verified |  BA is not what it used to be! ...\n2  ✅ Trip Verified |  BA First, it's not even the...\n3  ✅ Trip Verified |  The worst business class ex...\n4  Not Verified |  Quite possibly the worst busin...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reviews</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>✅ Trip Verified |  Absolutely horrible custome...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Not Verified |  BA is not what it used to be! ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>✅ Trip Verified |  BA First, it's not even the...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>✅ Trip Verified |  The worst business class ex...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Not Verified |  Quite possibly the worst busin...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.to_csv(\"BA_reviews.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-03-13T05:53:28.810354Z","iopub.execute_input":"2024-03-13T05:53:28.810769Z","iopub.status.idle":"2024-03-13T05:53:28.996211Z","shell.execute_reply.started":"2024-03-13T05:53:28.810721Z","shell.execute_reply":"2024-03-13T05:53:28.994711Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Congratulations! Now you have your dataset for this task! The loops above collected 3765 reviews by iterating through the paginated pages on the website. However, if you want to collect more data, try increasing the number of pages!\n\n The next thing that you should do is clean this data to remove any unnecessary text from each of the rows. For example, \"✅ Trip Verified\" can be removed from each row if it exists, as it's not relevant to what we want to investigate.","metadata":{}}]}
